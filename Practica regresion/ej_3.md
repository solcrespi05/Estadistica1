#   Ejercicio 3
Supongamos que tenemos un dataset $(ğ‘¥1,ğ‘¦1),..., (ğ‘¥ğ‘›,ğ‘¦ğ‘›)$ âˆˆ $R^2$ para $ğ‘› âˆˆ N$ y hacemos un modelo de regresiÃ³n lineal, donde $ğ‘¦_ğ‘– = ğ›½0 + ğ›½1_ğ‘¥_ğ‘– +ğœ€_ğ‘–$.
    (a) Mostrar que los valores de $ğ›½_0$ y $ğ›½_1$ que minimizan la suma de los residuos $\sum_{i=1}^{n}ğœ€_ğ‘–$ son

    $$
    \hat{\beta_1} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2}
    $$ ,
    $$ 
    \hat{\beta_0}  = \bar{y}- \hat{\beta_1} \bar{x}
    $$

    (b) Podemos demostrar que un estimador no sesgado de ğœ es
    $$
    \hat{\sigma^2} = \frac{1}{n-2}\sum_{i=1}^{n}(y_1 - \bar{y})^2
    $$

    Â¿CÃ³mo se interpreta el 2 que aparece restando en el denominador?
 
    (c)Â¿Que pasarÃ­a si hicieramos un ajuste de la forma $ğ‘Œ âˆ¼ ğ›½ğ‘‹$?